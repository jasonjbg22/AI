{
  "9": {
    "inputs": {
      "filename_prefix": "Flux2_Faceswap",
      "images": [
        "183",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "107": {
    "inputs": {
      "text": "head_swap: Use image 1 as the base image, preserving its environment, background, camera perspective, framing, exposure, contrast, and lighting. Remove the head from image 1 and seamlessly replace it with the head from image 2.\nMatch the original head size, face-to-body ratio, neck thickness, shoulder alignment, and camera distance so proportions remain natural and unchanged.\n\nAdapt the inserted head to the lighting of image 1 by matching light direction, intensity, softness, color temperature, shadows, and highlights, with no independent relighting.\nPreserve the identity of image 2, including hair texture, eye color, nose structure, facial proportions, and skin details.\nMatch the pose and expression from image 1, including head tilt, rotation, eye direction, gaze, micro-expressions, and lip position.\nEnsure seamless neck and jaw blending, consistent skin tone, realistic shadow contact, natural skin texture, and uniform sharpness.\nPhotorealistic, high quality, sharp details, 4K.",
      "clip": [
        "175",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "117": {
    "inputs": {
      "rgthree_comparer": {
        "images": [
          {
            "name": "A",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_bcxgx_00001_.png&type=temp&subfolder=&rand=0.6023447302755857"
          },
          {
            "name": "B",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_bcxgx_00002_.png&type=temp&subfolder=&rand=0.36525636693805286"
          }
        ]
      },
      "image_a": [
        "170:149",
        0
      ],
      "image_b": [
        "183",
        0
      ]
    },
    "class_type": "Image Comparer (rgthree)",
    "_meta": {
      "title": "Image Comparer (rgthree)"
    }
  },
  "118": {
    "inputs": {
      "conditioning": [
        "170:112",
        0
      ],
      "latent": [
        "119",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "119": {
    "inputs": {
      "pixels": [
        "120",
        0
      ],
      "vae": [
        "174",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "120": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": [
        "173",
        0
      ],
      "resolution_steps": 1,
      "image": [
        "121",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "121": {
    "inputs": {
      "image": "head_placeholder.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Head (Identity)"
    }
  },
  "151": {
    "inputs": {
      "image": "body_placeholder.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Body (Base)"
    }
  },
  "173": {
    "inputs": {
      "value": 2
    },
    "class_type": "PrimitiveFloat",
    "_meta": {
      "title": "Float (Set Megapixels)"
    }
  },
  "174": {
    "inputs": {
      "vae_name": "flux2-vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "175": {
    "inputs": {
      "clip_name": "qwen_3_8b_fp8mixed.safetensors",
      "type": "flux2",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "176": {
    "inputs": {
      "unet_name": "flux-2-klein-9b-fp8.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "177": {
    "inputs": {
      "lora_name": "bfs_head_v1_flux-klein_9b_step3500_rank128.safetensors",
      "strength_model": 1,
      "model": [
        "176",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "178": {
    "inputs": {
      "guidance": 4,
      "conditioning": [
        "118",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "179": {
    "inputs": {
      "conditioning": [
        "107",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "180": {
    "inputs": {
      "samples": [
        "170:150",
        0
      ],
      "mask": [
        "170:153",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask",
    "_meta": {
      "title": "Set Latent Noise Mask"
    }
  },
  "181": {
    "inputs": {
      "width": [
        "170:148",
        0
      ],
      "height": [
        "170:148",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptyFlux2LatentImage",
    "_meta": {
      "title": "Empty Flux 2 Latent"
    }
  },
  "182": {
    "inputs": {
      "switch": true,
      "on_false": [
        "180",
        0
      ],
      "on_true": [
        "181",
        0
      ]
    },
    "class_type": "ComfySwitchNode",
    "_meta": {
      "title": "Switch (Disable Inpainting)"
    }
  },
  "183": {
    "inputs": {
      "samples": [
        "172:168",
        0
      ],
      "vae": [
        "174",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "170:125": {
    "inputs": {
      "pixels": [
        "170:115",
        0
      ],
      "vae": [
        "174",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "170:147": {
    "inputs": {
      "samples": [
        "170:125",
        0
      ],
      "vae": [
        "174",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "170:115": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": [
        "173",
        0
      ],
      "resolution_steps": 1,
      "image": [
        "151",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "170:148": {
    "inputs": {
      "image": [
        "170:147",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "170:150": {
    "inputs": {
      "pixels": [
        "170:149",
        0
      ],
      "vae": [
        "174",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "170:112": {
    "inputs": {
      "conditioning": [
        "107",
        0
      ],
      "latent": [
        "170:150",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "170:149": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": [
        "170:148",
        0
      ],
      "height": [
        "170:148",
        1
      ],
      "crop": "center",
      "image": [
        "151",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "170:153": {
    "inputs": {
      "resize_type": "scale dimensions",
      "resize_type.width": [
        "170:148",
        0
      ],
      "resize_type.height": [
        "170:148",
        1
      ],
      "resize_type.crop": "center",
      "scale_method": "bicubic",
      "input": [
        "151",
        1
      ]
    },
    "class_type": "ResizeImageMaskNode",
    "_meta": {
      "title": "Resize Image/Mask"
    }
  },
  "170:160": {
    "inputs": {
      "mask": [
        "170:153",
        0
      ]
    },
    "class_type": "MaskPreview",
    "_meta": {
      "title": "Preview Mask"
    }
  },
  "172:168": {
    "inputs": {
      "seed": 31104633809678,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "LanPaint_NumSteps": 2,
      "LanPaint_PromptMode": "Image First",
      "LanPaint_Info": "LanPaint KSampler. For more info, visit https://github.com/scraed/LanPaint. If you find it useful, please give a star ‚≠êÔ∏è!",
      "Inpainting_mode": "üñºÔ∏è Image Inpainting",
      "model": [
        "177",
        0
      ],
      "positive": [
        "178",
        0
      ],
      "negative": [
        "179",
        0
      ],
      "latent_image": [
        "182",
        0
      ]
    },
    "class_type": "LanPaint_KSampler",
    "_meta": {
      "title": "LanPaint KSampler"
    }
  }
}
